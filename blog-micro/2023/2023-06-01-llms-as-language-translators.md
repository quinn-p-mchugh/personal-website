---
title: "LLMs: Translators of languages no human can understand"
slug: llms-as-translators
#description: 
#keywords: []
tags: [Productivity, Mental Health]
authors: qmchugh
#image: 
hide_table_of_contents: true
draft: false
---

I recently came across [this great introductory talk](https://youtu.be/xoVJKj8lcNQ) from the Center for Humane Technology, discussing the less catastrophic, but still significant risks of generative large language models (LLMs). This might be a valuable resource to share with those unfamiliar with the staggering pace of AI capabilities research.

**A key insight for me:**
Generative LLMs have the capacity to interpret an astonishing variety of languages. Whether those languages are traditional (e.g. written or verbal English) or abstract (e.g. images, electrical signals in the brain, wifi traffic, etc) doesn't necessarily matter. What matters is the events in that language can be quantified and measured.

While this opens up the door to numerous fascinating applications (e.g. translating animal vocalizations to human language, enabling blind individuals to see), it also raises some serious concerns regarding privacy of thought, mass surveillance, and further erosion of truth, among others.